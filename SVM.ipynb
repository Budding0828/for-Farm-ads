{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from preprocess import loadData\n",
    "from preprocess import cross_10folds\n",
    "from numpy import *\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_SVM(totdata_x, totdata_y):\n",
    "    res = 0.0\n",
    "    for j in range(0, 10):\n",
    "        train_x, train_y, test_x, test_y = cross_10folds(totdata_x, totdata_y, j)\n",
    "        model = svm.SVC(kernel='linear', C=1, gamma=1)\n",
    "        model.fit(train_x, train_y)\n",
    "        \n",
    "        right = 0\n",
    "        for i in range(test_x.shape[0]):\n",
    "            if(model.predict([test_x[i]])==test_y[i]):\n",
    "                right = right + 1\n",
    "        \n",
    "        res += right/test_y.shape[0]\n",
    "        print(\"第 %d 次的准确率为 %f\" %(j, right/test_y.shape[0]))\n",
    "    \n",
    "    print(\"最后的准确率为 %f\" %(res/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectJrand(i, m):\n",
    "    j=i;\n",
    "    while(j==i):\n",
    "        j = int(random.uniform(0,m))\n",
    "    return j\n",
    "\n",
    "def clipAlpha(aj, H, L):\n",
    "    if(aj>H):\n",
    "        aj = H\n",
    "    if(L>aj):\n",
    "        aj = L\n",
    "    return aj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernelTrans(X, A, kTup): #calc the kernel or transform data to a higher dimensional space\n",
    "    m,n = X.shape\n",
    "    K = mat(zeros((m,1)))\n",
    "    if (kTup[0]=='lin'): K = X * A.T   #linear kernel\n",
    "    elif (kTup[0]=='rbf'):\n",
    "        for j in range(m):\n",
    "            deltaRow = X[j,:] - A\n",
    "            \n",
    "            K[j] = deltaRow*deltaRow.T\n",
    "        K = exp(K/(-1*kTup[1]**2)) #divide in NumPy is element-wise not matrix like Matlab\n",
    "    else: \n",
    "        raise NameError('Houston We Have a Problem -- That Kernel is not recognized')\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optStruct:\n",
    "    def __init__(self,dataMatIn, classLabels, C, toler, kTup):  # Initialize the structure with the parameters \n",
    "        self.X = dataMatIn\n",
    "        self.labelMat = classLabels\n",
    "        self.C = C\n",
    "        self.tol = toler\n",
    "        self.m = dataMatIn.shape[0]\n",
    "        self.alphas = mat(zeros((self.m,1)))\n",
    "        self.b = 0\n",
    "        self.eCache = mat(zeros((self.m,2))) #first column is valid flag\n",
    "        self.K = mat(zeros((self.m,self.m)))\n",
    "        for i in range(self.m):\n",
    "            self.K[:,i] = kernelTrans(self.X, self.X[i,:], kTup)\n",
    "        \n",
    "def calcEk(oS, k):\n",
    "    fXk = float(multiply(oS.alphas,oS.labelMat).T*oS.K[:,k] + oS.b)\n",
    "    Ek = fXk - float(oS.labelMat[k])\n",
    "    return Ek\n",
    "        \n",
    "def selectJ(i, oS, Ei):         #this is the second choice -heurstic, and calcs Ej\n",
    "    maxK = -1; maxDeltaE = 0; Ej = 0\n",
    "    oS.eCache[i] = [1,Ei]  #set valid #choose the alpha that gives the maximum delta E\n",
    "    validEcacheList = nonzero(oS.eCache[:,0].A)[0]\n",
    "    if (len(validEcacheList) > 1):\n",
    "        for k in validEcacheList:   #loop through valid Ecache values and find the one that maximizes delta E\n",
    "            if (k == i): continue #don't calc for i, waste of time\n",
    "            Ek = calcEk(oS, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if (deltaE > maxDeltaE):\n",
    "                maxK = k; maxDeltaE = deltaE; Ej = Ek\n",
    "        return maxK, Ej\n",
    "    else:   #in this case (first time around) we don't have any valid eCache values\n",
    "        j = selectJrand(i, oS.m)\n",
    "        Ej = calcEk(oS, j)\n",
    "    return j, Ej\n",
    "\n",
    "def updateEk(oS, k):#after any alpha has changed update the new value in the cache\n",
    "    Ek = calcEk(oS, k)\n",
    "    oS.eCache[k] = [1,Ek]\n",
    "        \n",
    "def innerL(i, oS):\n",
    "    Ei = calcEk(oS, i)\n",
    "    if (((oS.labelMat[i]*Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i]*Ei > oS.tol) and (oS.alphas[i] > 0))):\n",
    "        j,Ej = selectJ(i, oS, Ei) #this has been changed from selectJrand\n",
    "        alphaIold = oS.alphas[i].copy(); alphaJold = oS.alphas[j].copy();\n",
    "        if (oS.labelMat[i] != oS.labelMat[j]):\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if (L==H): \n",
    "            #print (\"L==H\"); \n",
    "            return 0\n",
    "        eta = 2.0 * oS.K[i,j] - oS.K[i,i] - oS.K[j,j] #changed for kernel\n",
    "        if (eta >= 0): \n",
    "            #print (\"eta>=0\"); \n",
    "            return 0\n",
    "        oS.alphas[j] -= oS.labelMat[j]*(Ei - Ej)/eta\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j],H,L)\n",
    "        updateEk(oS, j) #added this for the Ecache\n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001): \n",
    "            #print (\"j not moving enough\"); \n",
    "            return 0\n",
    "        oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])#update i by the same amount as j\n",
    "        updateEk(oS, i) #added this for the Ecache                    #the update is in the oppostie direction\n",
    "        b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,i] - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[i,j]\n",
    "        b2 = oS.b - Ej- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,j]- oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[j,j]\n",
    "        if ((0 < oS.alphas[i]) and (oS.C > oS.alphas[i])): oS.b = b1\n",
    "        elif ((0 < oS.alphas[j]) and (oS.C > oS.alphas[j])): oS.b = b2\n",
    "        else: oS.b = (b1 + b2)/2.0\n",
    "        return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoP(dataMatIn, classLabels, C, toler, maxIter,kTup=('lin', 0)):    #full Platt SMO\n",
    "    oS = optStruct(mat(dataMatIn),mat(classLabels).transpose(),C,toler, kTup)\n",
    "    iters = 0\n",
    "    entireSet = True; alphaPairsChanged = 0\n",
    "    while ((iters < maxIter) and ((alphaPairsChanged > 0) or (entireSet))):\n",
    "        alphaPairsChanged = 0\n",
    "        if (entireSet):   #go over all\n",
    "            for i in range(oS.m):        \n",
    "                alphaPairsChanged += innerL(i,oS)\n",
    "                #print (\"fullSet, iter: %d i:%d, pairs changed %d\" % (iters,i,alphaPairsChanged))\n",
    "            iters += 1\n",
    "        else:#go over non-bound (railed) alphas\n",
    "            nonBoundIs = nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerL(i,oS)\n",
    "                #print (\"non-bound, iter: %d i:%d, pairs changed %d\" % (iters,i,alphaPairsChanged))\n",
    "            iters += 1\n",
    "        if (entireSet): entireSet = False #toggle entire set loop\n",
    "        elif (alphaPairsChanged == 0): entireSet = True  \n",
    "        #print (\"iteration number: %d\" % iters)\n",
    "    return oS.b,oS.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcWs(alphas,dataArr,classLabels):\n",
    "    X = mat(dataArr); labelMat = mat(classLabels).transpose()\n",
    "    m,n = X.shape\n",
    "    w = zeros((n,1))\n",
    "    for i in range(m):\n",
    "        w += multiply(alphas[i]*labelMat[i],X[i,:].T)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(train_x, train_y, test_x, test_y, k1=1.3):\n",
    "    \n",
    "    b,alphas = smoP(train_x, train_y, 200, 0.0001, 10000, ('rbf', k1)) #C=200 important\n",
    "    datMat=mat(train_x); labelMat = mat(train_y).transpose()\n",
    "    svInd=nonzero(alphas.A>0)[0]\n",
    "    sVs=datMat[svInd] #get matrix of only support vectors\n",
    "    labelSV = labelMat[svInd];\n",
    "    # print (\"there are %d Support Vectors\" % sVs.shape[0])\n",
    "    m,n = datMat.shape\n",
    "    errorCount = 0\n",
    "\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs,datMat[i,:],('rbf', k1))\n",
    "        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b\n",
    "        if (sign(predict)!=sign(train_y[i])): errorCount += 1\n",
    "    #print (\"the training error rate is: %f\" % (float(errorCount)/m))\n",
    "    \n",
    "    errorCount = 0\n",
    "    datMat=mat(test_x); labelMat = mat(test_y).transpose()\n",
    "    m,n = datMat.shape\n",
    "    for i in range(m):\n",
    "        kernelEval = kernelTrans(sVs,datMat[i,:],('rbf', k1))\n",
    "        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b\n",
    "        if (sign(predict)!=sign(test_y[i])): errorCount += 1    \n",
    "    #print (\"the test error rate is: %f\" % (float(errorCount)/m))\n",
    "    return (float(errorCount)/m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handwrite_SVM(totdata_x, totdata_y):\n",
    "    res = 0.0\n",
    "    for j in range(0, 10):\n",
    "        train_x, train_y, test_x, test_y = cross_10folds(totdata_x, totdata_y, j)\n",
    "        #print(train_x.shape)\n",
    "        #print(train_y.shape)\n",
    "        #print(test_x.shape)\n",
    "        #print(test_y.shape)\n",
    "        temp = test(train_x, train_y, test_x, test_y)\n",
    "        res = res + temp\n",
    "        print(\"第 %d 次的准确率为 %f\" %(j, temp))\n",
    "    \n",
    "    print(\"最后的准确率为 %f\" %(res/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test1]",
   "language": "python",
   "name": "conda-env-test1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
